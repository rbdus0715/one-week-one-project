{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3907f1e",
   "metadata": {},
   "source": [
    "# LSTM 모델을 이용한 NLP classification (스팸 메일 분류)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f502cd00",
   "metadata": {},
   "source": [
    "### 1.1 fc 복습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d765a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, num_output, input_size, hidden_size, device):\n",
    "        super(ANN, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.fc1(x).relu()\n",
    "        h = self.fc2(x).relu()\n",
    "        predict = self.outlayer(h)\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646a656b",
   "metadata": {},
   "source": [
    "### 1.2 LSTM for NLP\n",
    "- input layer : 정수 인코딩 된 결과\n",
    "- embed layer : word2vec 역할 -> nn.Embedding(단어 갯수, embed_dim)\n",
    "- LSTM  layer : nn.LSTM(embed_size, hidden_size, layer 수, dropout rate, bid/sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff41cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_net(nn.Module):\n",
    "    def __init__(self, num_output, size_vocab, dim_embed, hidden_size, linear_size, num_layers, device):\n",
    "        super(LSTM_net, self).__init__()\n",
    "        self.device = device\n",
    "        self.num_output = num_output # 1 : 이진 분류\n",
    "        self.hidden_size = hidden_size # 128\n",
    "        self.num_layers = num_layers # 2\n",
    "\n",
    "        self.embed = nn.Embedding(size_vocab, dim_embed)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = dim_embed, hidden_size = hidden_size,\n",
    "                           num_layers = num_layers, dropout = 0.3, bidirectional = True)\n",
    "        self.fclayer = nn.Linear(hidden_size, linear_size)\n",
    "        self.outlayer = nn.Linear(linear_size, num_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        scaler = 2 if self.lstm.bidirectional == True else 1\n",
    "        # x : 정수 인코딩 [batch, seq_len] -> word2vec 결과 : [batch, seq_len, dim_embed]\n",
    "        emb = self.embed(x)\n",
    "        # hidden state와 cell state 초기화 [num_layer x scaler, batch, hidden]\n",
    "        h_state = Variable(torch.zeros(self.num_layers*scaler, emb.size(0),\n",
    "                                      self.hidden_size, requires_grad=True))\n",
    "        c_state = Variable(torch.zeros(self.num_layers*scaler, emb.size(0),\n",
    "                                      self.hidden_size, requires_grad=True))\n",
    "        # emb : [seq_len, batch, dim_embed] \n",
    "        # lstm의 결과 : out, h, c 중 h만 사용\n",
    "        lstm_out, (h, c) = self.lstm(emb.transpose(1,0), (h_state, c_state))\n",
    "        # important : 마지막 time의 hidden만 사용하겠다\n",
    "        h = h[-1] \n",
    "        h = self.fclayer(h).relu()\n",
    "        predict = self.outlayer(h)\n",
    "        \n",
    "        return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258f01f0",
   "metadata": {},
   "source": [
    "### 1.3 Spam Mail Classification : 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079016da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 : 5572\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/10.%20RNN%20Text%20Classification/dataset/spam.csv\", filename=\"spam.csv\")\n",
    "data = pd.read_csv('spam.csv', encoding='latin1')\n",
    "print('총 샘플의 수 :',len(data))\n",
    "display(data.info(), data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb7a2691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data['Unnamed: 2']\n",
    "del data['Unnamed: 3']\n",
    "del data['Unnamed: 4']\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c1944d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2</th>\n",
       "      <th>v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  v2  v1\n",
       "0  Go until jurong point, crazy.. Available only ...   0\n",
       "1                      Ok lar... Joking wif u oni...   0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...   1\n",
       "3  U dun say so early hor... U c already then say...   0\n",
       "4  Nah I don't think he goes to usf, he lives aro...   0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['v1'] = data['v1'].replace(['ham','spam'],[0,1])\n",
    "data = data[['v2', 'v1']]\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc10fade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Go until jurong point, crazy.. Available only ...     0\n",
       "1                      Ok lar... Joking wif u oni...     0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3  U dun say so early hor... U c already then say...     0\n",
       "4  Nah I don't think he goes to usf, he lives aro...     0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = ['text','spam']\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920e3f12",
   "metadata": {},
   "source": [
    "### 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8c5516c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6388596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after cleaning : 5572\n"
     ]
    }
   ],
   "source": [
    "token_text = []\n",
    "for i in range(5572):\n",
    "    token = word_tokenize(data.iloc[i,0])\n",
    "    token_stop_text = []\n",
    "    for w in token:\n",
    "        if w not in stop_words:\n",
    "            token_stop_text.append(w)\n",
    "    token_text.append(token_stop_text)\n",
    "print('after cleaning :', len(token_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c25adf7d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Go',\n",
       "  'jurong',\n",
       "  'point',\n",
       "  ',',\n",
       "  'crazy',\n",
       "  '..',\n",
       "  'Available',\n",
       "  'bugis',\n",
       "  'n',\n",
       "  'great',\n",
       "  'world',\n",
       "  'la',\n",
       "  'e',\n",
       "  'buffet',\n",
       "  '...',\n",
       "  'Cine',\n",
       "  'got',\n",
       "  'amore',\n",
       "  'wat',\n",
       "  '...'],\n",
       " ['Ok', 'lar', '...', 'Joking', 'wif', 'u', 'oni', '...'],\n",
       " ['Free',\n",
       "  'entry',\n",
       "  '2',\n",
       "  'wkly',\n",
       "  'comp',\n",
       "  'win',\n",
       "  'FA',\n",
       "  'Cup',\n",
       "  'final',\n",
       "  'tkts',\n",
       "  '21st',\n",
       "  'May',\n",
       "  '2005',\n",
       "  '.',\n",
       "  'Text',\n",
       "  'FA',\n",
       "  '87121',\n",
       "  'receive',\n",
       "  'entry',\n",
       "  'question',\n",
       "  '(',\n",
       "  'std',\n",
       "  'txt',\n",
       "  'rate',\n",
       "  ')',\n",
       "  'T',\n",
       "  '&',\n",
       "  'C',\n",
       "  \"'s\",\n",
       "  'apply',\n",
       "  '08452810075over18',\n",
       "  \"'s\"]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98322b0a",
   "metadata": {},
   "source": [
    "### 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19d1c4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈도수 조사 : Bow\n",
    "word2inx = {}\n",
    "Bow = []\n",
    "for sentence in token_text:\n",
    "    for word in sentence:\n",
    "        if word not in word2inx.keys(): #  없으면\n",
    "            word2inx[word] = len(word2inx)\n",
    "            Bow.insert(len(word2inx)-1,1)\n",
    "        else: # 이미 있으면\n",
    "            inx = word2inx.get(word)\n",
    "            Bow[inx] += 1\n",
    "\n",
    "\n",
    "# vocab\n",
    "vocab = {}\n",
    "for n, v in enumerate(word2inx):\n",
    "    vocab[v] = Bow[n]\n",
    "    \n",
    "# 빈도수로 정렬하기\n",
    "# sorted 함수 : vocab.items()을 정렬 / 임시함수 x[1]를 리턴 / 오름차순,내림차순\n",
    "vocab_sort = sorted(vocab.items(), key=lambda x:x[1], reverse = True)\n",
    "\n",
    "# 많이 쓰이는 순서부터 인코딩\n",
    "word2inx = {word[0] : index + 1 for index, word in enumerate(vocab_sort)}\n",
    "\n",
    "# encoding\n",
    "for i, sentence in enumerate(token_text):\n",
    "    for j, word in enumerate(sentence):\n",
    "        token_text[i][j] = word2inx[word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b467d9db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[736, 5213, 847, 3, 848, 11, 2541, 1503, 49, 99, 413, 1318, 127, 3362, 6, 5214, 33, 5215, 122, 6]\n"
     ]
    }
   ],
   "source": [
    "print(token_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5881b9d3",
   "metadata": {},
   "source": [
    "### 학습을 위한 Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94dd6e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_label = np.array(data.iloc[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b2312b",
   "metadata": {},
   "source": [
    "### Padding 및 데이터 자르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d64b78cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572,)\n",
      "(5572,)\n",
      "(5572, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gyuyeonjo/opt/anaconda3/envs/deep_torch/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(token_text))\n",
    "print(np.shape(text_label))\n",
    "maxlen = 0\n",
    "for w in token_text:\n",
    "    if len(w)>= maxlen:\n",
    "        maxlen = len(w)\n",
    "\n",
    "# 단어 100개까지만 보자\n",
    "maxlen = 100\n",
    "rowdata = []\n",
    "for w in token_text:\n",
    "    if len(w) >= maxlen:\n",
    "        rowdata.append(w[:maxlen])\n",
    "    else:\n",
    "        rowdata.append(np.pad(w,(0, maxlen), 'constant', constant_values=0)[:maxlen])\n",
    "text_padded = np.concatenate(rowdata, axis=0).reshape(-1, maxlen)\n",
    "print(np.shape(text_padded))       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ff4d7",
   "metadata": {},
   "source": [
    "### 1.4 학습을 위한 Dataset 만들기 및 학습 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b27617a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch import LongTensor as LT\n",
    "from torch import FloatTensor as FT\n",
    "\n",
    "# torch(data).to(device) 작업을 해줌\n",
    "class Generate_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, xdata, ydata, device):\n",
    "        self.x_data = xdata\n",
    "        self.y_data = ydata\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = LT(self.x_data[idx]).to(self.device)\n",
    "        y = LT(self.y_data[idx]).to(self.device)\n",
    "        return x, y  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8d438",
   "metadata": {},
   "source": [
    "### Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02ed6b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Generate_Dataset(text_padded[:5000,:], text_label[:5000].reshape([-1,1]), device)\n",
    "trainset, testset = random_split(dataset, [4500, 500])\n",
    "train_loader = DataLoader(trainset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=500, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551cff29",
   "metadata": {},
   "source": [
    "### Define Network and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f938162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output : 2 (one-hot으로 binary 분류)\n",
    "\n",
    "lstm_net = LSTM_net(num_output = 2, size_vocab = len(word2inx), dim_embed = 64,\n",
    "                   hidden_size=64, linear_size=64, num_layers=1, device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm_net.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501106be",
   "metadata": {},
   "source": [
    "### Training Session\n",
    "- x : email word\n",
    "- predict size : [batch, 2] : 2는 원핫 인코딩이기 때문에\n",
    "- y : [batch, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5c02c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "tensor(0.1590, grad_fn=<NllLossBackward0>)\n",
      "Epoch 1\n",
      "tensor(0.0245, grad_fn=<NllLossBackward0>)\n",
      "Epoch 2\n",
      "tensor(0.0486, grad_fn=<NllLossBackward0>)\n",
      "Epoch 3\n",
      "tensor(0.0107, grad_fn=<NllLossBackward0>)\n",
      "Epoch 4\n",
      "tensor(0.0075, grad_fn=<NllLossBackward0>)\n",
      "Epoch 5\n",
      "tensor(6.5922e-05, grad_fn=<NllLossBackward0>)\n",
      "Epoch 6\n",
      "tensor(1.6995e-05, grad_fn=<NllLossBackward0>)\n",
      "Epoch 7\n",
      "tensor(4.4514e-05, grad_fn=<NllLossBackward0>)\n",
      "Epoch 8\n",
      "tensor(4.1579e-05, grad_fn=<NllLossBackward0>)\n",
      "Epoch 9\n",
      "tensor(3.4756e-05, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print('Epoch', epoch)\n",
    "    for x, y in train_loader:\n",
    "        predict = lstm_net(x)\n",
    "        loss = torch.nn.functional.cross_entropy(predict, y.ravel())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c40925",
   "metadata": {},
   "source": [
    "### Test the Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69bf5501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485 out of 500, accuracy is 97.0 %\n"
     ]
    }
   ],
   "source": [
    "for x, y in test_loader:\n",
    "    predict = lstm_net(x).argmax(1).detach().numpy()\n",
    "    answer = y.ravel().detach().numpy()\n",
    "score = 0\n",
    "for i in range(len(predict)):\n",
    "    if predict[i] == answer[i]:\n",
    "        score += 1\n",
    "print(score, 'out of 500, accuracy is', score/500*100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "deep_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
